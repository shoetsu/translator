# Text processing.
input_max_len = 30
output_max_len = 5
#vocab_size = 30000
vocab_size = 0
lowercase=true
num_columns=4
num_train_data=0

# Training.
max_to_keep = 1
max_epoch = 30
max_gradient_norm = 5.0
learning_rate = 0.001
decay_rate = 0.999
decay_frequency = 100
dropout_rate=0.2
train_embedding=true
teacher_forcing=false
batch_size=10

# Structure.
num_layers=1
rnn_size=50
rnn_type=bidirectional_dynamic_rnn
cell_type=GRUCell
model_type=PointerNetwork
#dataset_type=NumNormalizedPriceDataset
dataset_type=CurrencyNormalizedPriceDataset
#dataset_type=PriceDataset
#dataset_type=PriceDatasetWithFeatures

dataset_path {
  test = dataset/test.annotated.csv
  valid = dataset/test.annotated.csv
  #train = dataset/weak_label_9800_sep.csv
  #train = dataset/train.annotated.csv
  train = dataset/train.large.csv
  #train = dataset/train.large.only_dollar.csv
}

#Pretrained embeddings.
embedding_path=dataset/embeddings
embeddings=[${glove_300d_filtered}]
glove_300d_filtered {
  path = ${embedding_path}/glove.840B.300d.txt.filtered
  size = 300
  format = txt
}
